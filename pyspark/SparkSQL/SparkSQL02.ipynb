{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import abspath\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from  pyspark.sql.catalog import Catalog\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import LongType, StringType, DateType, IntegerType, FloatType, StructField, StructType\n",
    "from pyspark.sql.functions import udf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "warehousePath = abspath('spark_database')\n",
    "sparkv2path = '/home/doug/ProjetosEstudo/LearningSparkV2/databricks-datasets/learning-spark-v2/'\n",
    "sparkdefguidepath = '/home/doug/ProjetosEstudo/Spark-The-Definitive-Guide/data/'\n",
    "master= \"local[*]\"\n",
    "worker=\"172.28.170.236:37969\"\n",
    "\n",
    "spark = SparkSession.\\\n",
    "            builder.\\\n",
    "            appName('SparkSQLII').\\\n",
    "            master(master).\\\n",
    "            config(\"spark.sql.warehouse.dir\", warehousePath).\\\n",
    "            config(\"spark.sql.catalogImplementation\", \"hive\").\\\n",
    "            config(\"spark.sql.legacy.createHiveTableByDefault\", \"false\").\\\n",
    "            enableHiveSupport().\\\n",
    "        getOrCreate()\n",
    "            \n",
    "spark\n",
    "sampledata = abspath('/mnt/d/linux/datasource/data/flight-data/csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql('select 1')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceschema = StructType([\n",
    "                         StructField('InvoiceNo', IntegerType(), False),\n",
    "                         StructField('StockCode', StringType(), False),\n",
    "                         StructField('Description', StringType(), False),\n",
    "                         StructField('Quantity', IntegerType(), False),\n",
    "                         StructField('InvoiceDate', StringType(), False),\n",
    "                         StructField('UnitPrice', FloatType(), False),\n",
    "                         StructField('CustomerID', IntegerType(), False),\n",
    "                         StructField('Country', StringType(), False)])\n",
    "retailframe = spark.\\\n",
    "                read.\\\n",
    "                csv('/mnt/d/linux/datasource/data/retail-data/all/online-retail-dataset.csv',\\\n",
    "                            schema= sourceschema,\\\n",
    "                            header=True,\\\n",
    "                            sep=',',\n",
    "                            enforceSchema= False).\\\n",
    "                withColumnRenamed('InvoiceNo', 'invoiceid').\\\n",
    "                withColumnRenamed('StockCode', 'stockcode').\\\n",
    "                withColumnRenamed('Description', 'desc').\\\n",
    "                withColumnRenamed('Quantity', 'quantity').\\\n",
    "                withColumnRenamed('InvoiceDate', 'orderdate').\\\n",
    "                withColumnRenamed('UnitPrice', 'unitprice').\\\n",
    "                withColumnRenamed('CustomerID', 'customerid').\\\n",
    "                withColumnRenamed('Country', 'country')\n",
    "                \n",
    "retailframe.createOrReplaceTempView('vwretailframe')\n",
    "\n",
    "\n",
    "\n",
    "# InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleschema = StructType([\n",
    "                            StructField('DEST_COUNTRY_NAME', StringType(), True),\n",
    "                            StructField('ORIGIN_COUNTRY_NAME', StringType(), True),\n",
    "                            StructField('count', IntegerType(), True)\n",
    "                        \n",
    "                        ])\n",
    "\n",
    "\n",
    "sampleflight = spark.read.\\\n",
    "                    csv(f'{sampledata}/*.csv',\n",
    "                        header=True,\n",
    "                        schema= sampleschema,\n",
    "                        ).\\\n",
    "                    withColumnRenamed('DEST_COUNTRY_NAME', 'destine').\\\n",
    "                    withColumnRenamed('ORIGIN_COUNTRY_NAME', 'origin')\n",
    "                    \n",
    "sampleflight.createOrReplaceTempView(\"vflight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flightcount(frame:str, columns:str, quantity:str, country: str):\n",
    "    \n",
    "    \"\"\" function that calculate flights by country \"\"\"\n",
    "    \n",
    "    return spark.sql( \n",
    "              f\"\"\" \n",
    "              \n",
    "              select\n",
    "              \n",
    "                {columns}, \n",
    "                sum({quantity})\n",
    "                \n",
    "                from {frame}\n",
    "                where {columns} = '{country}'\n",
    "                group by {columns}\n",
    "                \n",
    "              \"\"\"\n",
    "            )\n",
    "    \n",
    "# totalcount('vflight', 'origin', 'count', 'India').show()\n",
    "unitedflight = flightcount('vflight', 'origin', 'count', 'United States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalfunction = udf(flightcount)\n",
    "\n",
    "frametable = spark.table('vflight')\n",
    "\n",
    "indiacount = frametable.select(totalfunction('frametable', 'origin', 'count', 'inidia'))\n",
    "indiacount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shretailframe = spark.sql(\"\"\" \n",
    "                            select\n",
    "                                invoiceid,\n",
    "                                orderdate,\n",
    "                                stockcode,\n",
    "                                quantity,\n",
    "                                unitprice,\n",
    "                                customerid,\n",
    "                                country\n",
    "                            from vwretailframe \"\"\")\n",
    "\n",
    "shretailframe.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared(s):\n",
    "    return s * s\n",
    "\n",
    "spark.udf.register('squared', squared, FloatType())\n",
    "\n",
    "powerprice = spark.sql(\"\"\"\n",
    "                       select \n",
    "                            cast(squared(unitprice) as numeric(12, 2)) as pwr_price\n",
    "                        from vwretailframe \"\"\")\n",
    "\n",
    "powerprice.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/24 14:28:13 WARN SimpleFunctionRegistry: The function doublecol replaced a previously registered function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|total|\n",
      "+-----+\n",
      "|15.30|\n",
      "|20.34|\n",
      "|22.00|\n",
      "|20.34|\n",
      "|20.34|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def doublecol (col1, col2):\n",
    "    \n",
    "    return col1 * col2\n",
    "\n",
    "spark.udf.register('doublecol', doublecol, FloatType())\n",
    "\n",
    "totalsell = spark.sql( \"\"\"\n",
    "                        select \n",
    "                            cast(doublecol(quantity, unitprice) as numeric(12,2)) as total\n",
    "                        from vwretailframe \"\"\")\n",
    "totalsell.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.range(1,30).createOrReplaceTempView(\"powerview\")\n",
    "\n",
    "spark.sql(\"\"\" select * from powerview \"\"\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(\"long\") # type: ignore\n",
    "def squared_fun(s):\n",
    "    return s ** 2\n",
    "\n",
    "df = spark.table(\"powerview\")\n",
    "df.select(\"id\", squared_fun(\"id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizando o UDF do módulo pyspark.sql.function, cria uma udf através de uma função\n",
    "#sem precisar registrar\n",
    "\n",
    "squaredfun = udf(squared, LongType())\n",
    "\n",
    "df = spark.range(0,20, 2).createOrReplaceTempView(\"rangeview\")\n",
    "\n",
    "nt = spark.table(\"rangeview\")\n",
    "nt.select(\"id\", squaredfun(\"id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/24 14:28:39 WARN SimpleFunctionRegistry: The function custclass replaced a previously registered function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+--------+\n",
      "|quantity|unitprice|  rating|\n",
      "+--------+---------+--------+\n",
      "|       6|     2.55|Rating A|\n",
      "|       6|     3.39|Rating A|\n",
      "|       8|     2.75|Rating A|\n",
      "|       6|     3.39|Rating A|\n",
      "|       6|     3.39|Rating A|\n",
      "|       2|     7.65|Rating A|\n",
      "|       6|     4.25|Rating A|\n",
      "|       6|     1.85|Rating A|\n",
      "|       6|     1.85|Rating A|\n",
      "|      32|     1.69|Rating A|\n",
      "|       6|      2.1|Rating A|\n",
      "|       6|      2.1|Rating A|\n",
      "|       8|     3.75|Rating A|\n",
      "|       6|     1.65|      No|\n",
      "|       6|     4.25|Rating A|\n",
      "|       3|     4.95|Rating A|\n",
      "|       2|     9.95|Rating A|\n",
      "|       3|     5.95|Rating A|\n",
      "|       3|     5.95|Rating A|\n",
      "|       4|     7.95|Rating A|\n",
      "+--------+---------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql(\"\"\" select * from vwretailframe \"\"\").show()\n",
    "\n",
    "def customerclass(colqnt, colprice):\n",
    "    \n",
    "    rating = colqnt * colprice\n",
    "    \n",
    "    if rating > 10.00:\n",
    "        return \"Rating A\"\n",
    "    else:\n",
    "        return \"No\"\n",
    "\n",
    "spark.udf.register('custclass', customerclass, StringType())\n",
    "\n",
    "# custclass = udf(customerclass, StringType())\n",
    "\n",
    "createclass = spark.sql(\"\"\" select \n",
    "                            quantity, \n",
    "                            \n",
    "                            unitprice,\n",
    "                            custclass(quantity, unitprice) as rating\n",
    "                        from vwretailframe \"\"\")\n",
    "\n",
    "createclass.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explicitando null check na função.\n",
    "datasmp =[\n",
    "        ('prod1', 10, 3.99),\n",
    "        ('prod1', 20, 3.99),\n",
    "        ('prod4', 5, 6.00),\n",
    "        ('prod4', 4, 6.00),\n",
    "        ('prod4', 5, 6.00),\n",
    "        ('prod1', 4, 3.99),\n",
    "        ('prod2', 5, 5.99),\n",
    "        ('prod2', 5, 5.99),\n",
    "        ('prod3', None, None),\n",
    "        ('prod3', None, None),\n",
    "        ('prod2', 5, 5.99)]\n",
    "\n",
    "schematype = StructType([\n",
    "                        StructField('produto', StringType(), True),\n",
    "                        StructField('quantidade', IntegerType(), True),\n",
    "                        StructField('preco', FloatType(), True)])\n",
    "\n",
    "frameproduto = spark.createDataFrame(datasmp, schematype).fillna(0)\n",
    "sampleprod = spark.createDataFrame(data= datasmp, schema= schematype).fillna(0).createOrReplaceTempView(\"sampleprod\")\n",
    "\n",
    "spark.sql(\"\"\" select * from sampleprod \"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#udf nullaware\n",
    "\n",
    "# frameproduto.fillna(0)\n",
    "\n",
    "def classprod(col_um, col_dois): \n",
    "    \n",
    "    total = col_um * col_dois\n",
    "    \n",
    "    if total > '50.00':\n",
    "        return 1.00\n",
    "   \n",
    "    elif total > '40.00' and total < '50.00':\n",
    "        return 2.00\n",
    "    \n",
    "    else:\n",
    "       return 3.00\n",
    "   \n",
    "spark.udf.register('classprod', classprod, FloatType())\n",
    "\n",
    "rt_prod = spark.sql(\"\"\" \n",
    "            \n",
    "                select \n",
    "                    produto,\n",
    "                    quantidade,\n",
    "                    preco,\n",
    "                    classprod(quantidade, produto) as rating\n",
    "                    \n",
    "                from sampleprod \"\"\")\n",
    "rt_prod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newclass = udf(classprod, StringType())\n",
    "\n",
    "# frameproduto.select('quantidade', 'preco', newclass('quantidade', 'preco')).show()\n",
    "\n",
    "\n",
    "frameproduto.selectExpr('quantidade * preco').show()\n",
    "\n",
    "frameproduto.fillna(0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
